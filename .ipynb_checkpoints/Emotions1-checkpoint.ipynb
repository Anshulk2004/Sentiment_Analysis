{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad65704-2365-4f66-b120-db472044f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4e67c8-dcdb-4d8b-b1d2-400c551cd5e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f0e39f-4ff7-45a3-b7e4-7dc07b79693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"emotions_dataset.txt\" , header=None , sep=\";\" , names=[\"Comment\" , \"Emotions\"] , encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144defdd-9295-488f-8fb8-303cb791fcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Comment Emotions\n",
       "0                                i didnt feel humiliated  sadness\n",
       "1      i can go from feeling so hopeless to so damned...  sadness\n",
       "2       im grabbing a minute to post i feel greedy wrong    anger\n",
       "3      i am ever feeling nostalgic about the fireplac...     love\n",
       "4                                   i am feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "15995  i just had a very brief time in the beanbag an...  sadness\n",
       "15996  i am now turning and i feel pathetic that i am...  sadness\n",
       "15997                     i feel strong and good overall      joy\n",
       "15998  i feel like this was such a rude comment and i...    anger\n",
       "15999  i know a lot but i feel so stupid because i ca...  sadness\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8506dd0-1fcc-453f-9f41-dcb0f3ba1b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(w) for w in train_data['Comment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e598f074-361e-4bba-a43d-02d6ac8f4f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\ANSHUL\n",
      "[nltk_data]     KUMAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53304eb4-ba37-47d6-8429-99babaa8057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca5f6913-3b77-4c36-9bf2-5df75de349f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "train_data[\"Emotions\"] = lb.fit_transform(train_data[\"Emotions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f32771e-19dd-4ad4-8248-56cdbd51a843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Emotions\n",
       "0                            i didnt feel humiliated         4\n",
       "1  i can go from feeling so hopeless to so damned...         4\n",
       "2   im grabbing a minute to post i feel greedy wrong         0\n",
       "3  i am ever feeling nostalgic about the fireplac...         3\n",
       "4                               i am feeling grouchy         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d705733-8b82-4c11-b74b-b8d8de167e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(df , column,vocab_size ,max_len):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    corpus = []\n",
    "\n",
    "    for text in df[column]:\n",
    "        text = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
    "        text = text.lower()\n",
    "        text = text.split()\n",
    "        text = [lemmatizer.lemmatize(word) for word in text if word not in stopwords]\n",
    "        text = \" \".join(text)\n",
    "        corpus.append(text)\n",
    "\n",
    "    one_hot_word = [one_hot(input_text=word , n=vocab_size) for word in corpus]\n",
    "    pad = pad_sequences(sequences=one_hot_word , maxlen=max_len,padding='pre')\n",
    "    return pad\n",
    "\n",
    "x_train = text_cleaning(train_data,\"Comment\",vocab_size=11000,max_len=300)\n",
    "y_train = to_categorical(train_data[\"Emotions\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86f5135b-42b5-48ab-9257-b23d1d2717c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "273e867f-885d-4df1-b4f9-5defa0f789a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ANSHUL KUMAR\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ba1ebb7-e5f2-4f47-a742-18493fefa4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 6907, 3331, 4123],\n",
       "       [   0,    0,    0, ..., 3527, 6098, 7104],\n",
       "       [   0,    0,    0, ..., 3331, 2180,  478],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 9935, 1674, 6372],\n",
       "       [   0,    0,    0, ..., 8444, 4649, 5039],\n",
       "       [   0,    0,    0, ..., 3331,  629, 2804]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "281cfe8e-37ef-426d-9396-a1c0b2cec193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e622b28-77c9-490b-a889-c9951fb6d035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ANSHUL KUMAR\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\ANSHUL KUMAR\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ANSHUL KUMAR\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "250/250 [==============================] - 87s 333ms/step - loss: 1.5371 - accuracy: 0.3838\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 90s 361ms/step - loss: 0.8321 - accuracy: 0.7007\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 80s 322ms/step - loss: 0.4647 - accuracy: 0.8499\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 78s 312ms/step - loss: 0.2819 - accuracy: 0.9069\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 73s 293ms/step - loss: 0.1975 - accuracy: 0.9377\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 76s 305ms/step - loss: 0.1473 - accuracy: 0.9517\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 77s 309ms/step - loss: 0.1183 - accuracy: 0.9613\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 73s 294ms/step - loss: 0.0936 - accuracy: 0.9696\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 79s 315ms/step - loss: 0.0797 - accuracy: 0.9739\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 81s 326ms/step - loss: 0.0661 - accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ee192a28d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=11000,output_dim=150,input_length=300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train , y_train , epochs=10 , batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebeefe2d-bc02-48f5-b496-fc493b35871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    corpus = []\n",
    "\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text if word not in stopwords]\n",
    "    text = \" \".join(text)\n",
    "    corpus.append(text)       \n",
    "\n",
    "    one_hot_word = [one_hot(input_text=word , n=11000) for word in corpus]\n",
    "    pad = pad_sequences(sequences=one_hot_word , maxlen=300,padding='pre')\n",
    "    return pad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca4792a9-efc0-4ffe-a231-7f744a392f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_emotion(input):\n",
    "    final_text = cleaning_text(input)\n",
    "    # final_text = np.array(final_text)\n",
    "\n",
    "    result = lb.inverse_transform(np.argmax(model.predict(final_text),axis=-1))\n",
    "    probability = np.max(model.predict(final_text))\n",
    "    print(f\"{result} : {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57c18e38-b107-4863-9c31-64c0404e3e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "['love'] : 0.8849857449531555\n"
     ]
    }
   ],
   "source": [
    "prediction_emotion(\"I am not loving to do this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5447c1c3-ac73-4417-b364-eecdad2f4c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANSHUL KUMAR\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model_emotion.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fe970a8-7d30-4be9-a62c-17bd01085ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lb1.pkl','wb') as f:\n",
    "    pickle.dump(lb,f)\n",
    "\n",
    "vocab_info = {'vocab_size': 11000 , 'max_len' : 300}\n",
    "with open('vocab_info.pkl','wb') as f:\n",
    "    pickle.dump(vocab_info,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
